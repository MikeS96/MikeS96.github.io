My BEng degree project addressed the problem of the autonomous landing of a UAV 
with a landing platform located on the top of a ground vehicle. The project 
utilized vision-based techniques to detect the landing platform, a Kalman 
filter was tailored for the tracking phase and finally, a PID controller sent 
control commands to the flight controller of the UAV to land properly on the 
platform. Rigorous assessments were conducted through the simulation of the 
whole robotic stack with ROS and gazebo in the software in the loop provided by 
PX4. Ultimately, the system was tested in a custom DJI F-450 and embedded in a 
Odroid XU4. The system demonstrates a satisfactory performance and was able to 
land with a mean error of ten centimeters from the center of the landing 
platform (Implemented in Python, C++/Linux).

Autonomous landing is a capability that is essential to achieve the full potential 
of multi-rotor drones in many social and industrial applications. The implementation 
and testing of this capability on physical platforms is risky and resource-intensive;
hence, in order to ensure both a sound design process and a safe deployment, 
simulations are required before implementing a physical prototype. This paper presents 
the development of a monocular visual system, using a software-in-the-loop methodology, 
that autonomously and efficiently lands a quadcopter drone on a predefined landing pad, 
thus reducing the risks of the physical testing stage. In addition to ensuring that 
the autonomous landing system as a whole fulfils the design requirements using a 
Gazebo-based simulation, our approach provides a tool for safe parameter tuning and 
design testing prior to physical implementation. Finally, the proposed monocular 
vision-only approach to landing pad tracking made it possible to effectively implement 
the system in an F450 quadcopter drone with the standard computational capabilities of 
an Odroid XU4 embedded processor.
